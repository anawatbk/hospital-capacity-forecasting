{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Final-Project-Check-in\" data-toc-modified-id=\"Final-Project-Check-in-1\">Final Project Check-in</a></span></li><li><span><a href=\"#Group-Name\" data-toc-modified-id=\"Group-Name-2\">Group Name</a></span></li><li><span><a href=\"#Student-Names\" data-toc-modified-id=\"Student-Names-3\">Student Names</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-4\">Load Data</a></span></li><li><span><a href=\"#Fit-scikit-learn-model\" data-toc-modified-id=\"Fit-scikit-learn-model-5\">Fit scikit-learn model</a></span></li><li><span><a href=\"#Evaluation-Metric\" data-toc-modified-id=\"Evaluation-Metric-6\">Evaluation Metric</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Project Check-in\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Anawat Putwanphen\n",
    "----------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research Question / Hypothesis\n",
    "----\n",
    "California COVID-19 Hospital bed capacity forecasting (weekly average).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import TransformerMixin, BaseEstimator, clone\n",
    "from sklearn.impute import *\n",
    "from imblearn.pipeline import make_pipeline #\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data_source_path = '../data/reported_hospital_capacity_admissions_facility_level_weekly_average_timeseries_20210228.csv'\n",
    "df = pd.read_csv(data_source_path, parse_dates = ['collection_week'])\\\n",
    "       .query('state == \"CA\"').sort_values(by=['hospital_pk', 'collection_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_pipeline_preprocessing(df):\n",
    "    '''\n",
    "    All Preprocessing process which are not supported by Pipeline\n",
    "    1. drop rows of inconsistent covid cases report,\n",
    "       For example, covid cases > combined cases (which consist of non-covid + covid cases)\n",
    "    2. select rows of hospital who report covid cases in the last 4 months\n",
    "       (2020-11-06 until 2021-02-19) \n",
    "    '''\n",
    "    ### Drop all inconsistent covid cases report rows \n",
    "    inconsistent_hospital_pk = df[(\n",
    "        (df['inpatient_beds_used_7_day_sum'] / df['inpatient_beds_used_7_day_sum']) <\n",
    "        (df['total_pediatric_patients_hospitalized_confirmed_and_suspected_covid_7_day_sum']\n",
    "            / df['total_pediatric_patients_hospitalized_confirmed_and_suspected_covid_7_day_coverage'])\n",
    "        )]['hospital_pk'].unique()\n",
    "    df = df[~np.isin(df['hospital_pk'], inconsistent_hospital_pk)]\n",
    "\n",
    "    #### keep only the hospitals who reported capacity every week for the last 4 month (2020-11-06 until 2021-02-19)\n",
    "    max_week_count = df.loc[df['collection_week'] > '2020-11-01']\\\n",
    "                       .groupby('hospital_pk').count().max()['collection_week']\n",
    "    hospital_pk_array = df.loc[df['collection_week'] > '2020-11-01']\\\n",
    "                          .groupby('hospital_pk').count().index.values\n",
    "    complete_hostital_mask = (df.loc[df['collection_week'] > '2020-11-01']\\\n",
    "                                .groupby('hospital_pk').count()['collection_week'] == max_week_count)\n",
    "    hospital_pk_array = hospital_pk_array[complete_hostital_mask]\n",
    "    df = df[np.isin(df['hospital_pk'], hospital_pk_array)].copy()\n",
    "    return df\n",
    "    \n",
    "def pre_pipeline_generate_multi_step_y(df):\n",
    "    '''\n",
    "    generate  1 month-ahead (4 step-ahead) output target.\n",
    "    \n",
    "    y | y+1 | y+2 | y+3\n",
    "    '''\n",
    "    \n",
    "    # transform target y into 4-step-ahead\n",
    "    y = df[['hospital_pk', 'inpatient_beds_used_7_day_sum', \n",
    "            'inpatient_beds_used_7_day_coverage']].copy()\n",
    "    y['inpatient_bed_used'] = (y['inpatient_beds_used_7_day_sum'] / \n",
    "                               y['inpatient_beds_used_7_day_coverage'])\n",
    "    y['inpatient_bed_used'] = y['inpatient_bed_used'].fillna(0)\n",
    "    y.loc[y['inpatient_bed_used'] < 0, 'inpatient_bed_used'] = 0 \n",
    "\n",
    "    step_ahead = 3 # y_t, y_t+1, y_t+2, y_t+3\n",
    "    step_backward = 4\n",
    "    col = 'inpatient_bed_used'\n",
    "    for step in range(1, step_ahead+1):\n",
    "        y = y.assign(**{f'{col}+{step}': y.groupby('hospital_pk').shift(-step)[col]})\n",
    "    for step in range(1, step_backward+1):\n",
    "        y = y.assign(**{f'{col}-{step}': y.groupby('hospital_pk').shift(step)[col]})\n",
    "    # drop last 4 week of each hospital \n",
    "    y = y.drop(['inpatient_beds_used_7_day_sum', \n",
    "                'inpatient_beds_used_7_day_coverage', 'hospital_pk'], \n",
    "               axis=1)\n",
    "    no_target_week_mask = y.isnull().sum(axis=1) > 0\n",
    "    df = df[~no_target_week_mask].copy()\n",
    "    y = y.dropna()\n",
    "    y = y[['inpatient_bed_used', 'inpatient_bed_used+1', \n",
    "           'inpatient_bed_used+2', 'inpatient_bed_used+3']]\n",
    "    df['inpatient_bed_used'] = y['inpatient_bed_used']\n",
    "    return df.reset_index(drop=True), y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateCalculatedColumns(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" A DataFrame transformer that provides column selection\n",
    "    \n",
    "    Allows to select columns by name from pandas dataframes in scikit-learn\n",
    "    pipelines.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    columns : list of str, names of the dataframe columns to select\n",
    "        Default: [] \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        \"\"\" Selects columns of a DataFrame\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        \n",
    "        trans : pandas DataFrame\n",
    "            contains selected columns of X      \n",
    "        \"\"\"\n",
    "        self.before_shape = X.shape\n",
    "        # Inpatient Bed Capacity\n",
    "        X['inpatient_bed_capacity'] = X['inpatient_beds_7_day_sum'] / X['inpatient_beds_7_day_coverage']\n",
    "        # ICU Bed Capacity\n",
    "        X['icu_bed_capacity'] = X['total_icu_beds_7_day_sum'] / X['total_icu_beds_7_day_coverage']\n",
    "        # Inpatient Bed Used\n",
    "        X['inpatient_bed_used'] = X['inpatient_beds_used_7_day_sum'] / X['inpatient_beds_used_7_day_coverage']\n",
    "        # Adult covid inpatient   \n",
    "        X['adult_inpatients_confirmed_n_suspected_covid'] = (\n",
    "            X['total_adult_patients_hospitalized_confirmed_and_suspected_covid_7_day_sum'] \n",
    "             / X['total_adult_patients_hospitalized_confirmed_and_suspected_covid_7_day_coverage'])\n",
    "        # Pediatric covid inpatient   \n",
    "        X['pediatric_inpatrients_confirmed_n_suspected_covid'] = (\n",
    "            X['total_pediatric_patients_hospitalized_confirmed_and_suspected_covid_7_day_sum']\n",
    "            / X['total_pediatric_patients_hospitalized_confirmed_and_suspected_covid_7_day_coverage'])\n",
    "        # total covid inpatient (adult+pediatric)\n",
    "        X['total_inpatients_confirmed_n_suspected_covid'] = (\n",
    "            X['adult_inpatients_confirmed_n_suspected_covid'] \n",
    "            + X['pediatric_inpatrients_confirmed_n_suspected_covid'])\n",
    "        # elimanates -999999 error from data source\n",
    "        X.loc[X['total_inpatients_confirmed_n_suspected_covid'] < 0, 'total_inpatients_confirmed_n_suspected_covid'] = 0\n",
    "        X.loc[X['inpatient_bed_used'] < 0, 'inpatient_bed_used'] = 0\n",
    "        \n",
    "        trans = X.copy() \n",
    "        self.after_shape = trans.shape\n",
    "        return trans\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        \"\"\" Do nothing function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "        y : default None\n",
    "                \n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        self  \n",
    "        \"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectColumnsTransfomer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" A DataFrame transformer that provides column selection\n",
    "    \n",
    "    Allows to select columns by name from pandas dataframes in scikit-learn\n",
    "    pipelines.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    columns : list of str, names of the dataframe columns to select\n",
    "        Default: [] \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, columns=[], feature=False):\n",
    "        self.columns = columns\n",
    "        self.feature = feature\n",
    "    def transform(self, X, **transform_params):\n",
    "        \"\"\" Selects columns of a DataFrame\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        \n",
    "        trans : pandas DataFrame\n",
    "            contains selected columns of X      \n",
    "        \"\"\"\n",
    "        if self.feature:\n",
    "            X = X.drop(self.columns, axis=1)\n",
    "            return X\n",
    "        else: \n",
    "            X = X[self.columns].copy() \n",
    "            return X\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        \"\"\" Do nothing function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "        y : default None\n",
    "                \n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        self  \n",
    "        \"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateLagValues(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" A DataFrame transformer that provides column selection\n",
    "    \n",
    "    Allows to select columns by name from pandas dataframes in scikit-learn\n",
    "    pipelines.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    columns : list of str, names of the dataframe columns to select\n",
    "        Default: [] \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, columns=[], lags=4):\n",
    "        self.columns = columns\n",
    "        self.lags = lags\n",
    "    def transform(self, X, **transform_params):\n",
    "        \"\"\" Selects columns of a DataFrame\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        \n",
    "        trans : pandas DataFrame\n",
    "            contains selected columns of X      \n",
    "        \"\"\"\n",
    "        self.before_shape = X.shape\n",
    "        \n",
    "        for col in self.columns:\n",
    "            for lag in range(1, self.lags+1):\n",
    "                X = X.assign(**{f'{col}-{lag}': X.groupby('hospital_pk').shift(lag)[col]})\n",
    "        \n",
    "        return X.drop(self.columns, axis=1)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        \"\"\" Do nothing function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "        y : default None\n",
    "                \n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        self  \n",
    "        \"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupByImputer(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    using median of group to impute (hospital_pk)\n",
    "    fill by 0 if all values in the group are Nan\n",
    "    '''\n",
    "    def __init__(self, group_column, targets=[]):\n",
    "        self.group_column = group_column\n",
    "        self.targets = targets\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        impute_map = X.groupby(self.group_column)[self.targets].median().reset_index(drop=False)\n",
    "        self.impute_map_ = impute_map\n",
    "        \n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        X = X.copy()\n",
    "        \n",
    "        for index, row in self.impute_map_.iterrows(): # loop through each hospital\n",
    "            group_mask = row[self.group_column] == X[self.group_column]\n",
    "            for col in self.targets:\n",
    "                X.loc[group_mask, col] = X.loc[group_mask, col].fillna(row[col])\n",
    "        X[self.targets] = X[self.targets].fillna(0)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_columns = [\n",
    "    'hospital_pk', 'collection_week', 'hospital_subtype', 'is_metro_micro',\n",
    "    'inpatient_bed_capacity', 'icu_bed_capacity', \n",
    "    'inpatient_bed_used', 'total_inpatients_confirmed_n_suspected_covid']\n",
    "\n",
    "non_feature_columns = ['hospital_pk', 'collection_week', \n",
    "                       'inpatient_bed_capacity', 'icu_bed_capacity']\n",
    "\n",
    "time_dependant_columns = ['inpatient_bed_used', 'total_inpatients_confirmed_n_suspected_covid']\n",
    "\n",
    "df = pre_pipeline_preprocessing(df)\n",
    "X_original, y_original = pre_pipeline_generate_multi_step_y(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series train/test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_split(X, y):\n",
    "    test_start_date =  X.collection_week.max()\n",
    "    train_last_date  = test_start_date - pd.to_timedelta(4,unit='W')    \n",
    "    test_idxs = X.loc[X.collection_week >= test_start_date].index\n",
    "    train_idx = X.loc[X.collection_week <= train_last_date].index\n",
    "    X_test, y_test = X.loc[test_idxs], y.loc[test_idxs]\n",
    "    X_train, y_train = X.loc[train_idx], y.loc[train_idx]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def time_series_cv(X, y):\n",
    "    '''\n",
    "    Time Series cross validation\n",
    "    '''\n",
    "    X = X.reset_index(drop=True)\n",
    "    valid_start_date =  X.collection_week.max()\n",
    "    train_last_date  = valid_start_date - pd.to_timedelta(4,unit='W') \n",
    "    valid_idxs = X.loc[X.collection_week >= valid_start_date].index\n",
    "    train_idx = X.loc[X.collection_week <= train_last_date].index\n",
    "    return [list(train_idx), list(valid_idxs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = time_series_split(X_original, y_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit ML models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from   sklearn.compose            import *\n",
    "from   sklearn.ensemble           import RandomForestRegressor \n",
    "from   sklearn.experimental       import enable_iterative_imputer\n",
    "from   sklearn.impute             import *\n",
    "from   sklearn.metrics            import balanced_accuracy_score # Evaluation metric 2.0 \n",
    "from   sklearn.pipeline           import Pipeline\n",
    "from   sklearn.preprocessing      import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cat_cols = ['hospital_subtype', 'is_metro_micro']\n",
    "feature_con_cols = ['inpatient_bed_used-1', 'inpatient_bed_used-2',\n",
    "                    'inpatient_bed_used-3', 'inpatient_bed_used-4',\n",
    "                    'total_inpatients_confirmed_n_suspected_covid-1',\n",
    "                    'total_inpatients_confirmed_n_suspected_covid-2',\n",
    "                    'total_inpatients_confirmed_n_suspected_covid-3',\n",
    "                    'total_inpatients_confirmed_n_suspected_covid-4']\n",
    "\n",
    "con_pipe = Pipeline([('scaler', StandardScaler())]) \n",
    "\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\", add_indicator=True)),\n",
    "                     ('ohe', OneHotEncoder())])\n",
    "\n",
    "to_feature = ColumnTransformer([('continuous',  con_pipe, feature_con_cols),\n",
    "                                ('categorical', cat_pipe, feature_cat_cols)])\n",
    "\n",
    "# Final pipeline\n",
    "pipeline = Pipeline([('calculateColumns', CreateCalculatedColumns()),\n",
    "                             ('selectColumns_1', SelectColumnsTransfomer(relevant_columns)),\n",
    "                             ('createTimelag', GenerateLagValues(time_dependant_columns)),\n",
    "                             ('custom_imputer', GroupByImputer('hospital_pk', targets=feature_con_cols)),\n",
    "                             ('selectColumns_2', SelectColumnsTransfomer(non_feature_columns, feature=True)),\n",
    "                             ('finalProcessing', to_feature)])\n",
    "                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('calculateColumns', CreateCalculatedColumns()),\n",
       "                ('selectColumns_1',\n",
       "                 SelectColumnsTransfomer(columns=['hospital_pk',\n",
       "                                                  'collection_week',\n",
       "                                                  'hospital_subtype',\n",
       "                                                  'is_metro_micro',\n",
       "                                                  'inpatient_bed_capacity',\n",
       "                                                  'icu_bed_capacity',\n",
       "                                                  'inpatient_bed_used',\n",
       "                                                  'total_inpatients_confirmed_n_suspected_covid'])),\n",
       "                ('createTimelag',\n",
       "                 GenerateLagValues(columns=['inpatie...\n",
       "                                                   'total_inpatients_confirmed_n_suspected_covid-1',\n",
       "                                                   'total_inpatients_confirmed_n_suspected_covid-2',\n",
       "                                                   'total_inpatients_confirmed_n_suspected_covid-3',\n",
       "                                                   'total_inpatients_confirmed_n_suspected_covid-4']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 strategy='most_frequent')),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['hospital_subtype',\n",
       "                                                   'is_metro_micro'])]))])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate set --> week: 2021-01-22\n",
    "date_mask = (df_features['collection_week'] == '2021-01-22')\n",
    "\n",
    "validate = df_features.loc[date_mask].drop('collection_week', axis=1)\n",
    "train = df_features.loc[~date_mask].drop('collection_week', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target: inpatient_bed_used\n",
    "X_train = train.drop(['inpatient_bed_used', 'ratio_covid_inpatients', 'total_inpatients_confirmed_n_suspected_covid'], axis=1).copy()\n",
    "y_train = train['inpatient_bed_used'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target: inpatient_bed_used\n",
    "X_test = validate.drop(['inpatient_bed_used', 'ratio_covid_inpatients', 'total_inpatients_confirmed_n_suspected_covid'], axis=1).copy()\n",
    "y_test = validate['inpatient_bed_used'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ((X_train.dtypes == object) | (X_train.dtypes == bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('continuous',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  hospital_subtype                                      False\n",
       "inpatient_bed_used_lag_1                               True\n",
       "inpatient_bed_used_lag_2                               True\n",
       "inpatient_bed_used_lag_3                               True\n",
       "inpatient_bed_used_lag_4                               True\n",
       "is_metro_micro                                        False\n",
       "ratio_cov...\n",
       "ratio_covid_inpatients_lag_4                          False\n",
       "total_inpatients_confirmed_n_suspected_covid_lag_1    False\n",
       "total_inpatients_confirmed_n_suspected_covid_lag_2    False\n",
       "total_inpatients_confirmed_n_suspected_covid_lag_3    False\n",
       "total_inpatients_confirmed_n_suspected_covid_lag_4    False\n",
       "dtype: bool)])),\n",
       "                ('classifier',\n",
       "                 RandomForestRegressor(min_samples_leaf=9, n_estimators=200,\n",
       "                                       n_jobs=-1))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\", add_indicator=True)),\n",
    "                     ('ohe', OneHotEncoder())\n",
    "                     ])\n",
    "con_pipe = Pipeline([('imputer', SimpleImputer(strategy='median', add_indicator=True)),\n",
    "                      ('scaler', StandardScaler())])  \n",
    "preprocessing = ColumnTransformer([('continuous',  con_pipe, ~categorical_columns),\n",
    "                                   ('categorical', cat_pipe,  categorical_columns)])\n",
    "# regressor\n",
    "reg = RandomForestRegressor(n_estimators=200, min_samples_leaf=9, n_jobs=-1) \n",
    "\n",
    "pipe = Pipeline([('preprocessing', preprocessing), \n",
    "                 ('classifier', reg)])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metric\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Predicted value: 149.54\n"
     ]
    }
   ],
   "source": [
    "# check mean of predicted value\n",
    "print(f'Average Predicted value: {y_test.mean():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 10.80\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {mae:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
