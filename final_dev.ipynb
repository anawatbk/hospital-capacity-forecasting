{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/anawatbk/hospital-capacity-forecasting/blob/main/final_dev.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Group-Name\" data-toc-modified-id=\"Group-Name-2\">Group Name</a></span></li><li><span><a href=\"#Student-Names\" data-toc-modified-id=\"Student-Names-3\">Student Names</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-4\">Load Data</a></span></li><li><span><a href=\"#Fit-scikit-learn-model\" data-toc-modified-id=\"Fit-scikit-learn-model-5\">Fit scikit-learn model</a></span></li><li><span><a href=\"#Evaluation-Metric\" data-toc-modified-id=\"Evaluation-Metric-6\">Evaluation Metric</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Anawat Putwanphen\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research Question / Hypothesis\n",
    "----\n",
    "California COVID-19 Hospital bed capacity forecasting (weekly average).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COVID-19 Reported Patient Impact and Hospital Capacity by Facility by Department of Health and Human Services\n",
    "<br>\n",
    "https://healthdata.gov/dataset/covid-19-reported-patient-impact-and-hospital-capacity-facility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose            import *\n",
    "from sklearn.preprocessing      import *\n",
    "from sklearn.base import TransformerMixin, BaseEstimator, clone\n",
    "from sklearn.impute import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Lasso, SGDRegressor\n",
    "from sklearn.impute import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data_source_path = '../data/reported_hospital_capacity_admissions_facility_level_weekly_average_timeseries_20210228.csv'\n",
    "df = pd.read_csv(data_source_path, parse_dates = ['collection_week'])\\\n",
    "       .query('state == \"CA\"').sort_values(by=['hospital_pk', 'collection_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_pipeline_preprocessing(df):\n",
    "    '''\n",
    "    All Preprocessing process which are not supported by Pipeline\n",
    "    1. drop rows of inconsistent covid cases report,\n",
    "       For example, covid cases > combined cases (which consist of non-covid + covid cases)\n",
    "    2. select rows of hospital who report covid cases in the last 4 months\n",
    "       (2020-11-06 until 2021-02-19) \n",
    "    '''\n",
    "    # Drop all inconsistent covid cases report rows \n",
    "    inconsistent_hospital_pk = df[(\n",
    "        (df['inpatient_beds_used_7_day_sum'] / df['inpatient_beds_used_7_day_sum']) <\n",
    "        (df['total_pediatric_patients_hospitalized_confirmed_and_suspected_covid_7_day_sum']\n",
    "            / df['total_pediatric_patients_hospitalized_confirmed_and_suspected_covid_7_day_coverage'])\n",
    "        )]['hospital_pk'].unique()\n",
    "    df = df[~np.isin(df['hospital_pk'], inconsistent_hospital_pk)]\n",
    "\n",
    "    # keep only the hospitals who reported capacity every week for the last 4 month (2020-11-06 until 2021-02-19)\n",
    "    max_week_count = df.loc[df['collection_week'] > '2020-11-01']\\\n",
    "                       .groupby('hospital_pk').count().max()['collection_week']\n",
    "    hospital_pk_array = df.loc[df['collection_week'] > '2020-11-01']\\\n",
    "                          .groupby('hospital_pk').count().index.values\n",
    "    complete_hostital_mask = (df.loc[df['collection_week'] > '2020-11-01']\\\n",
    "                                .groupby('hospital_pk').count()['collection_week'] == max_week_count)\n",
    "    hospital_pk_array = hospital_pk_array[complete_hostital_mask]\n",
    "    df = df[np.isin(df['hospital_pk'], hospital_pk_array)].copy()\n",
    "    return df\n",
    "    \n",
    "def pre_pipeline_generate_multi_step_y(df):\n",
    "    '''\n",
    "    generate  1 month-ahead (4 step-ahead) output target.\n",
    "    \n",
    "    y | y+1 | y+2 | y+3\n",
    "    '''\n",
    "    \n",
    "    # Transform target y into 4-step-ahead\n",
    "    y = df[['hospital_pk', 'inpatient_beds_used_7_day_sum', \n",
    "            'inpatient_beds_used_7_day_coverage']].copy()\n",
    "    y['inpatient_bed_used'] = (y['inpatient_beds_used_7_day_sum'] / \n",
    "                               y['inpatient_beds_used_7_day_coverage'])\n",
    "    y['inpatient_bed_used'] = y['inpatient_bed_used'].fillna(0)\n",
    "    y.loc[y['inpatient_bed_used'] < 0, 'inpatient_bed_used'] = 0 \n",
    "\n",
    "    step_ahead = 3 # y_t, y_t+1, y_t+2, y_t+3\n",
    "    step_backward = 4\n",
    "    col = 'inpatient_bed_used'\n",
    "    for step in range(1, step_ahead+1):\n",
    "        y = y.assign(**{f'{col}+{step}': y.groupby('hospital_pk').shift(-step)[col]})\n",
    "    ##for step in range(1, step_backward+1):\n",
    "    ##    y = y.assign(**{f'{col}-{step}': y.groupby('hospital_pk').shift(step)[col]})\n",
    "    # Drop last 4 week of each hospital \n",
    "    y = y.drop(['inpatient_beds_used_7_day_sum', \n",
    "                'inpatient_beds_used_7_day_coverage', 'hospital_pk'], \n",
    "               axis=1)\n",
    "    no_target_week_mask = y.isnull().sum(axis=1) > 0\n",
    "    df = df[~no_target_week_mask].copy()\n",
    "    y = y.dropna()\n",
    "    y = y[['inpatient_bed_used', 'inpatient_bed_used+1', \n",
    "           'inpatient_bed_used+2', 'inpatient_bed_used+3']]\n",
    "    df['inpatient_bed_used'] = y['inpatient_bed_used']\n",
    "    return df.reset_index(drop=True), y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateCalculatedColumns(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" A DataFrame transformer that provides column selection\n",
    "    \n",
    "    Allows to select columns by name from pandas dataframes in scikit-learn\n",
    "    pipelines.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    columns : list of str, names of the dataframe columns to select\n",
    "        Default: [] \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        \"\"\" Selects columns of a DataFrame\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        \n",
    "        trans : pandas DataFrame\n",
    "            contains selected columns of X      \n",
    "        \"\"\"\n",
    "        self.before_shape = X.shape\n",
    "        # Inpatient Bed Capacity\n",
    "        X['inpatient_bed_capacity'] = X['inpatient_beds_7_day_sum'] / X['inpatient_beds_7_day_coverage']\n",
    "        # ICU Bed Capacity\n",
    "        X['icu_bed_capacity'] = X['total_icu_beds_7_day_sum'] / X['total_icu_beds_7_day_coverage']\n",
    "        # Inpatient Bed Used\n",
    "        X['inpatient_bed_used'] = X['inpatient_beds_used_7_day_sum'] / X['inpatient_beds_used_7_day_coverage']\n",
    "        # Adult covid inpatient   \n",
    "        X['adult_inpatients_confirmed_n_suspected_covid'] = (\n",
    "            X['total_adult_patients_hospitalized_confirmed_and_suspected_covid_7_day_sum'] \n",
    "             / X['total_adult_patients_hospitalized_confirmed_and_suspected_covid_7_day_coverage'])\n",
    "        # Pediatric covid inpatient   \n",
    "        X['pediatric_inpatrients_confirmed_n_suspected_covid'] = (\n",
    "            X['total_pediatric_patients_hospitalized_confirmed_and_suspected_covid_7_day_sum']\n",
    "            / X['total_pediatric_patients_hospitalized_confirmed_and_suspected_covid_7_day_coverage'])\n",
    "        # total covid inpatient (adult+pediatric)\n",
    "        X['total_inpatients_confirmed_n_suspected_covid'] = (\n",
    "            X['adult_inpatients_confirmed_n_suspected_covid'] \n",
    "            + X['pediatric_inpatrients_confirmed_n_suspected_covid'])\n",
    "        # elimanates -999999 error from data source\n",
    "        X.loc[X['total_inpatients_confirmed_n_suspected_covid'] < 0, 'total_inpatients_confirmed_n_suspected_covid'] = 0\n",
    "        X.loc[X['inpatient_bed_used'] < 0, 'inpatient_bed_used'] = 0\n",
    "        # Average Inpatient Bed Used\n",
    "        avg_inpatient_bed_used = X.groupby('hospital_pk').mean()[['inpatient_bed_used']]\\\n",
    "                                  .rename(columns={'inpatient_bed_used':'avg_inpatient_bed_used'})\n",
    "        X = X.join(avg_inpatient_bed_used, on='hospital_pk')\n",
    "        trans = X.copy() \n",
    "        self.after_shape = trans.shape\n",
    "        return trans\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        \"\"\" Do nothing function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "        y : default None\n",
    "                \n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        self  \n",
    "        \"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectColumnsTransfomer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" A DataFrame transformer that provides column selection\n",
    "    \n",
    "    Allows to select columns by name from pandas dataframes in scikit-learn\n",
    "    pipelines.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    columns : list of str, names of the dataframe columns to select\n",
    "        Default: [] \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, columns=[], feature=False):\n",
    "        self.columns = columns\n",
    "        self.feature = feature\n",
    "    def transform(self, X, **transform_params):\n",
    "        \"\"\" Selects columns of a DataFrame\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        \n",
    "        trans : pandas DataFrame\n",
    "            contains selected columns of X      \n",
    "        \"\"\"\n",
    "        if self.feature:\n",
    "            X = X.drop(self.columns, axis=1)\n",
    "            return X\n",
    "        else: \n",
    "            X = X[self.columns].copy() \n",
    "            return X\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        \"\"\" Do nothing function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "        y : default None\n",
    "                \n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        self  \n",
    "        \"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateLagValues(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" A DataFrame transformer that provides column selection\n",
    "    \n",
    "    Allows to select columns by name from pandas dataframes in scikit-learn\n",
    "    pipelines.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    columns : list of str, names of the dataframe columns to select\n",
    "        Default: [] \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, columns=[], lags=4):\n",
    "        self.columns = columns\n",
    "        self.lags = lags\n",
    "    def transform(self, X, **transform_params):\n",
    "        \"\"\" Selects columns of a DataFrame\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        \n",
    "        trans : pandas DataFrame\n",
    "            contains selected columns of X      \n",
    "        \"\"\"\n",
    "        self.before_shape = X.shape\n",
    "        \n",
    "        for col in self.columns:\n",
    "            for lag in range(1, self.lags+1):\n",
    "                X = X.assign(**{f'{col}-{lag}': X.groupby('hospital_pk').shift(lag)[col]})\n",
    "        \n",
    "        for col in self.columns:\n",
    "            X = X.assign(delta_4 =  X[f'{col}-{1}'] - X[f'{col}-{self.lags}'])\n",
    "        return X.drop(self.columns, axis=1)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        \"\"\" Do nothing function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "        y : default None\n",
    "                \n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        self  \n",
    "        \"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupByImputer(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    using median of group to impute (hospital_pk)\n",
    "    fill by 0 if all values in the group are Nan\n",
    "    '''\n",
    "    def __init__(self, group_column, targets=[]):\n",
    "        self.group_column = group_column\n",
    "        self.targets = targets\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        impute_map = X.groupby(self.group_column)[self.targets].median().reset_index(drop=False)\n",
    "        self.impute_map_ = impute_map\n",
    "        \n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        X = X.copy()\n",
    "        \n",
    "        for index, row in self.impute_map_.iterrows(): # loop through each hospital\n",
    "            group_mask = row[self.group_column] == X[self.group_column]\n",
    "            for col in self.targets:\n",
    "                X.loc[group_mask, col] = X.loc[group_mask, col].fillna(row[col])\n",
    "        X[self.targets] = X[self.targets].fillna(0)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyEstimator(BaseEstimator):\n",
    "    def fit(self): pass\n",
    "    def score(self): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_columns = [\n",
    "    'hospital_pk', 'collection_week', 'hospital_subtype', 'is_metro_micro',\n",
    "    'inpatient_bed_capacity', 'icu_bed_capacity', \n",
    "    'inpatient_bed_used', 'avg_inpatient_bed_used',\n",
    "    'total_inpatients_confirmed_n_suspected_covid',\n",
    "    ]\n",
    "\n",
    "non_feature_columns = ['hospital_pk', 'collection_week', \n",
    "                       'inpatient_bed_capacity', 'icu_bed_capacity']\n",
    "\n",
    "time_dependant_columns = ['inpatient_bed_used', 'total_inpatients_confirmed_n_suspected_covid']\n",
    "\n",
    "df = pre_pipeline_preprocessing(df)\n",
    "X_original, y_original = pre_pipeline_generate_multi_step_y(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series train/test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_split(X, y):\n",
    "    test_start_date =  X.collection_week.max()\n",
    "    train_last_date  = test_start_date - pd.to_timedelta(4,unit='W')    \n",
    "    test_idxs = X.loc[X.collection_week >= test_start_date].index\n",
    "    train_idx = X.loc[X.collection_week <= train_last_date].index\n",
    "    X_test, y_test = X.loc[test_idxs], y.loc[test_idxs]\n",
    "    X_train, y_train = X.loc[train_idx], y.loc[train_idx]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def time_series_cv(X, y):\n",
    "    '''\n",
    "    Time Series cross validation\n",
    "    '''\n",
    "    X = X.reset_index(drop=True)\n",
    "    valid_start_date =  X.collection_week.max()\n",
    "    train_last_date  = valid_start_date - pd.to_timedelta(4,unit='W') \n",
    "    valid_idxs = X.loc[X.collection_week >= valid_start_date].index\n",
    "    train_idx = X.loc[X.collection_week <= train_last_date].index\n",
    "    return [tuple([list(train_idx), list(valid_idxs)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = time_series_split(X_original, y_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit scikit-learn model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. RandomForestRegressor (Multi-output)\n",
    "2. GradientBoostingRegressor  (Multi-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cat_cols = ['hospital_subtype', 'is_metro_micro']\n",
    "feature_con_cols = ['inpatient_bed_used-1', 'inpatient_bed_used-2',\n",
    "                    'inpatient_bed_used-3', 'inpatient_bed_used-4',\n",
    "                    'total_inpatients_confirmed_n_suspected_covid-1',\n",
    "                    'total_inpatients_confirmed_n_suspected_covid-2',\n",
    "                    'total_inpatients_confirmed_n_suspected_covid-3',\n",
    "                    'total_inpatients_confirmed_n_suspected_covid-4',\n",
    "                    'avg_inpatient_bed_used', 'delta_4']\n",
    "\n",
    "con_pipe = Pipeline([('scaler', StandardScaler())]) \n",
    "\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\", add_indicator=True)),\n",
    "                     ('ohe', OneHotEncoder())])\n",
    "\n",
    "to_feature = ColumnTransformer([('continuous',  con_pipe, feature_con_cols),\n",
    "                                ('categorical', cat_pipe, feature_cat_cols)])\n",
    "\n",
    "# Final pipeline\n",
    "pipeline = Pipeline([('calculateColumns', CreateCalculatedColumns()),\n",
    "                             ('selectColumns_1', SelectColumnsTransfomer(relevant_columns)),\n",
    "                             ('createTimelag', GenerateLagValues(time_dependant_columns)),\n",
    "                             ('custom_imputer', GroupByImputer('hospital_pk', targets=feature_con_cols)),\n",
    "                             ('selectColumns_2', SelectColumnsTransfomer(non_feature_columns, feature=True)),\n",
    "                             ('finalProcessing', to_feature),\n",
    "                             ('model', DummyEstimator)])\n",
    "                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Best Models\n",
    "cv_time_series = time_series_cv(X_train, y_train)\n",
    "hyperparameters = [{'model': [Lasso(max_iter=3000)],\n",
    "                    'model__alpha': np.arange(0.001,11,10)},\n",
    "                   \n",
    "                   {'model': [SGDRegressor(max_iter=3000, early_stopping=True)],\n",
    "                    'model__loss': ['squared_loss', 'huber'],\n",
    "                    'model__penalty': ['l2', 'elasticnet'],\n",
    "                    'model__alpha': np.arange(0.001,11,10)},\n",
    "                   \n",
    "                   {'model': [RandomForestRegressor()],\n",
    "                    'model__n_estimators': np.arange(25, 301, 25),\n",
    "                    'model__max_depth': np.arange(5,31,5),\n",
    "                    'model__min_samples_leaf': np.arange(1,16,3)},\n",
    "    \n",
    "                    {'model': [GradientBoostingRegressor()],\n",
    "                     'model__loss': ['ls', 'huber'],\n",
    "                     'model__n_estimators': np.arange(25,301,25),\n",
    "                     'model__max_depth': np.arange(5,31,5),\n",
    "                     'model__subsample': [0.8,0.9,1.0],\n",
    "                     'model__min_samples_leaf': np.arange(1,16,3)}]\n",
    "\n",
    "regr_rand_cv = RandomizedSearchCV(estimator=pipeline, \n",
    "                              param_distributions=hyperparameters, \n",
    "                              n_iter=30, \n",
    "                              cv=cv_time_series, \n",
    "                              scoring='neg_mean_absolute_error',\n",
    "                              n_jobs=-1,\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 30 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bank/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [         nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan -12.96169515\n",
      "          nan          nan          nan          nan          nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=[([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,\n",
       "                         16, 17, 18, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, ...],\n",
       "                        [22, 45, 68, 91, 114, 137, 160, 183, 206, 229, 252, 275,\n",
       "                         298, 321, 344, 367, 390, 413, 436, 459, 482, 505, 528,\n",
       "                         551, 574, 597, 620, 643, 666, 689, ...])],\n",
       "                   estimator=Pipeline(steps=[('calculateColumns',\n",
       "                                              CreateCalculatedColumns()),\n",
       "                                             ('selectColumns_1',\n",
       "                                              SelectColumnsTransfomer(...\n",
       "                                         'model__n_estimators': array([ 25,  50,  75, 100, 125, 150, 175, 200, 225, 250, 275, 300])},\n",
       "                                        {'model': [GradientBoostingRegressor()],\n",
       "                                         'model__loss': ['ls', 'huber'],\n",
       "                                         'model__max_depth': array([ 5, 10, 15, 20, 25, 30]),\n",
       "                                         'model__min_samples_leaf': array([ 1,  4,  7, 10, 13]),\n",
       "                                         'model__n_estimators': array([ 25,  50,  75, 100, 125, 150, 175, 200, 225, 250, 275, 300]),\n",
       "                                         'model__subsample': [0.8, 0.9, 1.0]}],\n",
       "                   scoring='neg_mean_absolute_error', verbose=True)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_rand_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metric\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__n_estimators': 150,\n",
       " 'model__min_samples_leaf': 13,\n",
       " 'model__max_depth': 30,\n",
       " 'model': RandomForestRegressor(max_depth=30, min_samples_leaf=13, n_estimators=150)}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_rand_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.852630000668665"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regr_rand_cv.best_estimator_.predict(X_test)\n",
    "mean_absolute_error(y_test.values, y_pred, multioutput='uniform_average')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
